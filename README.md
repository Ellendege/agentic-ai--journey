# Agentic AI Journey â€” My First AI Agent (Hugging Face Course)

> **From learning to building.** This repo tracks my journey after finishing the **Hugging Face Agentic AI course** â€” building my first AI agent, experimenting with **LangChain**, **SmolAgents**, and **LangGraph**, and documenting real-world lessons about **model selection**, **tool creation**, and **debugging**.

---

## ðŸ”Ž Whatâ€™s inside

- **docs/**
  - `SmolAgents-Troubleshooting.md` â€” errors, causes, fixes, and minimal checks.
  - `LangChain-Troubleshooting.md` â€” common pitfalls + solutions.
  - `KNOWN_GOOD_MODELS.md` â€” models + tasks that worked for me (with notes).
  - `SAFE_PLAN.md` â€” my â€œstabilize-firstâ€ workflow for avoiding rabbit holes.
- **code/**
  - `app_langchain_baseline.py` â€” minimal LangChain baseline (HuggingFaceEndpoint).
  - `app_smolagents_baseline.py` â€” minimal SmolAgents baseline (InferenceClient).
- **notion/**
  - `NOTION_issues_combined.csv` â€” import-ready log database for Notion.
- **linkedin/**
  - `POST_TEMPLATES.md` â€” short posts (hooks, lessons, CTAs) to share progress.
- `PROGRESS_JOURNAL.md` â€” day-by-day notes linking errors â†’ fixes â†’ artifacts.
- `.github/ISSUE_TEMPLATE/learning-log.md` â€” capture each session quickly.

---

## ðŸŽ¯ Why this repo exists

- Show **hands-on progress** after the course (not just theory).
- Prove **debugging + communication**: problem â†’ root cause â†’ fix.
- Help others avoid the same traps (versions, imports, model/task mismatch).
- Create a public record I can reference in **Notion / GitHub / LinkedIn**.

---

## âš™ï¸ Quick start (local)

1) **Python env**
```bash
python -m venv .venv
# Windows
.\.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate
python -m pip install --upgrade pip

Install

pip install -r requirements_suggestion.txt
# After a clean run:
pip freeze > requirements.txt

Secrets

# Windows (setx then open a new terminal)
setx HUGGINGFACEHUB_API_TOKEN "<your-token>"
setx HF_MODEL_ID "google/flan-t5-large"

# macOS/Linux (current shell)
export HUGGINGFACEHUB_API_TOKEN="<your-token>"

ðŸ§ª Highlights: what I learned (short)

Versions matter: match imports to the exact package version; pin working sets.

Model â†” task compatibility: some models only support conversational, others text-generation or text2text-generation.

Tool outputs: agents fail if tools return None or unexpected types â†’ guard returns.

GAIA compliance: return only the final answer string; avoid debug logs in output.

Safe Plan: baseline first (no tools) â†’ add one tool at a time â†’ freeze versions.

See full details in docs/SmolAgents-Troubleshooting.md and docs/LangChain-Troubleshooting.md.

export HF_MODEL_ID="google/flan-t5-large"

| Model                                | Provider     | Task                 | Notes                               |
| ------------------------------------ | ------------ | -------------------- | ----------------------------------- |
| `google/flan-t5-large`               | HF Inference | text2text-generation | Stable baseline                     |
| `google/flan-t5-xl`                  | HF Inference | text2text-generation | Increase `max_new_tokens` as needed |
| `mistralai/Mistral-7B-Instruct-v0.3` | HF Inference | text-generation      | Instruction-tuned                   |


python code/app_langchain_baseline.py
python code/app_smolagents_baseline.py
